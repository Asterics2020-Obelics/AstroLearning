@PROCEEDINGS{Ryzhikov2017,
author = {A. Ryzhikov and A. Ustyuzhanin},
title = "Domain adaptation with gradient reversal for MC/real data calibration",
url={https://indico.cern.ch/event/567550/contributions/2629724/attachments/1513629/2515121/ACAT_PROCEEDINGS_2017.pdf},
year = 2017,
abstract = "It is quite common part of the data analysis in High Energy Physics to train a classifier for
signal and background separation. In case the signal under investigation is a rare process, the
signal sample is simulated and background sample is taken from the real data. Such setting
create an unnecessary bias: the classifier might learn not the characteristic of the signal but
the characteristic of the imperfect simulation. So the challenge is to train the classifier in such
way that it picks up signal/background difference and doesnt overfit to the simulation-specific
features. The suggested approach is based on cross-domain adaptation technique using neural
networks with gradient reversal. The network architecture is a dense multi-branch structure.
One branch is responsible for the signal/background discrimination, the second branch helps
to avoid the overfitting on the Monte-Carlo training dataset. The tests showed that this
architecture is a robust mechanism for choosing trade-offs between discrimination power and
overfitting. So the resulting networks successfully distinguishes the signal from the background,
but does not distinguish simulated events from the real ones. The third network branch helps
to reduce the correlation between the classifier predictions and reconstructed mass of the decay,
thereby making such approach highly viable for wide variety of physics searches"
}



@ARTICLE{2018arXiv180107323N,
   author = {{Narayan}, G. and {Zaidi}, T. and {Soraisam}, M.~D. and {Wang}, Z. and
	{Lochner}, M. and {Matheson}, T. and {Saha}, A. and {Yang}, S. and
	{Zhao}, Z. and {Kececioglu}, J. and {Scheidegger}, C. and {Snodgrass}, R.~T. and
	{Axelrod}, T. and {Jenness}, T. and {Maier}, R.~S. and {Ridgway}, S.~T. and
	{Seaman}, R.~L. and {Evans}, E.~M. and {Singh}, N. and {Taylor}, C. and
	{Toeniskoetter}, J. and {Welch}, E. and {Zhu}, S.},
    title = "{Machine Learning-based Brokers for Real-time Classification of the LSST Alert Stream}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1801.07323},
 primaryClass = "astro-ph.IM",
 keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Astrophysics - Cosmology and Nongalactic Astrophysics, Astrophysics - High Energy Astrophysical Phenomena},
     year = 2018,
    month = jan,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180107323N},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  abstract = "The unprecedented volume and rate of transient events that will be discovered by the Large Synoptic Survey Telescope (LSST) demands that the astronomical community update its followup paradigm. Alert-brokers -- automated software system to sift through, characterize, annotate and prioritize events for followup -- will be critical tools for managing alert streams in the LSST era. The Arizona-NOAO Temporal Analysis and Response to Events System (ANTARES) is one such broker. In this work, we develop a machine learning pipeline to characterize and classify variable and transient sources only using the available multiband optical photometry. We describe three illustrative stages of the pipeline, serving the three goals of early, intermediate and retrospective classification of alerts. The first takes the form of variable vs transient categorization, the second, a multi-class typing of the combined variable and transient dataset, and the third, a purity-driven subtyping of a transient class. While several similar algorithms have proven themselves in simulations, we validate their performance on real observations for the first time. We quantitatively evaluate our pipeline on sparse, unevenly sampled, heteroskedastic data from various existing observational campaigns, and demonstrate very competitive classification performance. We describe our progress towards adapting the pipeline developed in this work into a real-time broker working on live alert streams from time-domain surveys."
}

@article{GEORGE201864,
title = "Deep Learning for real-time gravitational wave detection and parameter estimation: Results with Advanced LIGO data",
journal = "Physics Letters B",
volume = "778",
pages = "64 - 70",
year = "2018",
issn = "0370-2693",
doi = "https://doi.org/10.1016/j.physletb.2017.12.053",
url = "http://www.sciencedirect.com/science/article/pii/S0370269317310390",
author = "Daniel George and E.A. Huerta",
keywords = "Deep Learning, Convolutional neural networks, Gravitational waves, LIGO, Time-series signal processing, Classification and regression",
abstract = "The recent Nobel-prize-winning detections of gravitational waves from merging black holes and the subsequent detection of the collision of two neutron stars in coincidence with electromagnetic observations have inaugurated a new era of multimessenger astrophysics. To enhance the scope of this emergent field of science, we pioneered the use of deep learning with convolutional neural networks, that take time-series inputs, for rapid detection and characterization of gravitational wave signals. This approach, Deep Filtering, was initially demonstrated using simulated LIGO noise. In this article, we present the extension of Deep Filtering using real data from LIGO, for both detection and parameter estimation of gravitational waves from binary black hole mergers using continuous data streams from multiple LIGO detectors. We demonstrate for the first time that machine learning can detect and estimate the true parameters of real events observed by LIGO. Our results show that Deep Filtering achieves similar sensitivities and lower errors compared to matched-filtering while being far more computationally efficient and more resilient to glitches, allowing real-time processing of weak time-series signals in non-stationary non-Gaussian noise with minimal resources, and also enables the detection of new classes of gravitational wave sources that may go unnoticed with existing detection algorithms. This unified framework for data analysis is ideally suited to enable coincident detection campaigns of gravitational waves and their multimessenger counterparts in real-time."
}

@ARTICLE{2017arXiv171107468G,
   author = {{George}, D. and {Shen}, H. and {Huerta}, E.~A.},
    title = "{Glitch Classification and Clustering for LIGO with Deep Transfer Learning}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1711.07468},
 primaryClass = "astro-ph.IM",
 keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Computer Science - Learning, General Relativity and Quantum Cosmology, Statistics - Machine Learning},
     year = 2017,
    month = nov,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171107468G},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  abstract="The detection of gravitational waves with LIGO and Virgo requires a detailed understanding of the response of these instruments in the presence of environmental and instrumental noise. Of particular interest is the study of anomalous non-Gaussian noise transients known as glitches, since their high occurrence rate in LIGO/Virgo data can obscure or even mimic true gravitational wave signals. Therefore, successfully identifying and excising glitches is of utmost importance to detect and characterize gravitational waves. In this article, we present the first application of Deep Learning combined with Transfer Learning for glitch classification, using real data from LIGO's first discovery campaign labeled by Gravity Spy, showing that knowledge from pre-trained models for real-world object recognition can be transferred for classifying spectrograms of glitches. We demonstrate that this method enables the optimal use of very deep convolutional neural networks for glitch classification given small unbalanced training datasets, significantly reduces the training time, and achieves state-of-the-art accuracy above 98.8\%. Once trained via transfer learning, we show that the networks can be truncated and used as feature extractors for unsupervised clustering to automatically group together new classes of glitches and anomalies. This novel capability is of critical importance to identify and remove new types of glitches which will occur as the LIGO/Virgo detectors gradually attain design sensitivity."
}


@ARTICLE{2018arXiv180310698S,
   author = {{Shilon}, I. and {Kraus}, M. and {B{\"u}chele}, M. and {Egberts}, K. and
	{Fischer}, T. and {Lukas Holch}, T. and {Lohse}, T. and {Schwanke}, U. and
	{Steppa}, C. and {Funk}, S.},
    title = "{Application of Deep Learning methods to analysis of Imaging Atmospheric Cherenkov Telescopes data}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1803.10698},
 primaryClass = "astro-ph.IM",
 keywords = {Astrophysics - Instrumentation and Methods for Astrophysics},
     year = 2018,
    month = mar,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180310698S},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  abstract="Ground based gamma-ray observations with Imaging Atmospheric Cherenkov Telescopes (IACTs) play a significant role in the discovery of very high energy (E > 100 GeV) gamma-ray emitters. The analysis of IACT data demands a highly efficient background rejection technique, as well as methods to accurately determine the energy of the recorded gamma-ray and the position of its source in the sky. We present results for background rejection and signal direction reconstruction from first studies of a novel data analysis scheme for IACT measurements. The new analysis is based on a set of Convolutional Neural Networks (CNNs) applied to images from the four H.E.S.S. phase-I telescopes. As the H.E.S.S. cameras pixels are arranged in a hexagonal array, we demonstrate two ways to use such image data to train CNNs: by resampling the images to a square grid and by applying modified convolution kernels that conserve the hexagonal grid properties. The networks were trained on sets of Monte-Carlo simulated events and tested on both simulations and measured data from the H.E.S.S. array. A comparison between the CNN analysis to current state-of-the-art algorithms reveals a clear improvement in background rejection performance. When applied to H.E.S.S. observation data, the CNN direction reconstruction performs at a similar level as traditional methods. These results serve as a proof-of-concept for the application of CNNs to the analysis of events recorded by IACTs."
}

@ARTICLE{2018arXiv180406913D,
   author = {{Duarte}, J. and {Han}, S. and {Harris}, P. and {Jindariani}, S. and
	{Kreinar}, E. and {Kreis}, B. and {Ngadiuba}, J. and {Pierini}, M. and
	{Rivera}, R. and {Tran}, N. and {Wu}, Z.},
    title = "{Fast inference of deep neural networks in FPGAs for particle physics}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1804.06913},
 primaryClass = "physics.ins-det",
 keywords = {Physics - Instrumentation and Detectors, Computer Science - Computer Vision and Pattern Recognition, High Energy Physics - Experiment, Statistics - Machine Learning},
     year = 2018,
    month = apr,
   adsurl = {http://adsabs.harvard.edu/abs/2018arXiv180406913D},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  abstract = "Recent results at the Large Hadron Collider (LHC) have pointed to enhanced physics capabilities through the improvement of the real-time event processing techniques. Machine learning methods are ubiquitous and have proven to be very powerful in LHC physics, and particle physics as a whole. However, exploration of the use of such techniques in low-latency, low-power FPGA hardware has only just begun. FPGA-based trigger and data acquisition (DAQ) systems have extremely low, sub-microsecond latency requirements that are unique to particle physics. We present a case study for neural network inference in FPGAs focusing on a classifier for jet substructure which would enable, among many other physics scenarios, searches for new dark sector particles and novel measurements of the Higgs boson. While we focus on a specific example, the lessons are far-reaching. We develop a package based on High-Level Synthesis (HLS) called hls4ml to build machine learning models in FPGAs. The use of HLS increases accessibility across a broad user community and allows for a drastic decrease in firmware development time. We map out FPGA resource usage and latency versus neural network hyperparameters to identify the problems in particle physics that would benefit from performing neural network inference with FPGAs. For our example jet substructure model, we fit well within the available resources of modern FPGAs with a latency on the scale of 100 ns."
}




@InProceedings{10.1007/978-3-319-23461-8_7,
author="Bockermann, Christian
and Br{\"u}gge, Kai
and Buss, Jens
and Egorov, Alexey
and Morik, Katharina
and Rhode, Wolfgang
and Ruhe, Tim",
editor="Bifet, Albert
and May, Michael
and Zadrozny, Bianca
and Gavalda, Ricard
and Pedreschi, Dino
and Bonchi, Francesco
and Cardoso, Jaime
and Spiliopoulou, Myra",
title="Online Analysis of High-Volume Data Streams in Astroparticle Physics",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="100--115",
abstract="Experiments in high-energy astroparticle physics produce large amounts of data as continuous high-volume streams. Gaining insights from the observed data poses a number of challenges to data analysis at various steps in the analysis chain of the experiments. Machine learning methods have already cleaved their way selectively at some particular stages of the overall data mangling process.",
isbn="978-3-319-23461-8"
}



@article{feng_lin_2016, title={The analysis of VERITAS muon images using convolutional neural networks}, volume={12}, DOI={10.1017/S1743921316012734}, number={S325}, journal={Proceedings of the International Astronomical Union}, publisher={Cambridge University Press}, author={Feng, Qi and Lin, Tony T. Y.}, year={2016}, pages={173–179},
abstract="Imaging atmospheric Cherenkov telescopes (IACTs) are sensitive to rare gamma-ray photons, buried in the background of charged cosmic-ray (CR) particles, the flux of which is several orders of magnitude greater. The ability to separate gamma rays from CR particles is important, as it is directly related to the sensitivity of the instrument. This gamma-ray/CR-particle classification problem in IACT data analysis can be treated with the rapidly-advancing machine learning algorithms, which have the potential to outperform the traditional box-cut methods on image parameters. We present preliminary results of a precise classification of a small set of muon events using a convolutional neural networks model with the raw images as input features. We also show the possibility of using the convolutional neural networks model for regression problems, such as the radius and brightness measurement of muon events, which can be used to calibrate the throughput efficiency of IACTs."
}

@ARTICLE{2017arXiv170806706C,
   author = {{Caron}, S. and {G{\'o}mez-Vargas}, G.~A. and {Hendriks}, L. and
	{Ruiz de Austri}, R.},
    title = "{Analyzing $\{$$\backslash$gamma$\}$-rays of the Galactic Center with Deep Learning}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1708.06706},
 primaryClass = "astro-ph.HE",
 keywords = {Astrophysics - High Energy Astrophysical Phenomena, High Energy Physics - Phenomenology},
     year = 2017,
    month = aug,
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv170806706C},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System},
  abstract="We present a new method to interpret the $\gamma$-ray data of our inner Galaxy as measured by the Fermi Large Area Telescope (Fermi LAT). We train and test convolutional neural networks with simulated Fermi-LAT images based on models tuned to real data. We use this method to investigate the origin of an excess emission of GeV $\gamma$-rays seen in previous studies. Interpretations of this excess include $\gamma$ rays created by the annihilation of dark matter particles and $\gamma$ rays originating from a collection of unresolved point sources, such as millisecond pulsars. Our new method allows precise measurements of the contribution and properties of an unresolved population of $\gamma$-ray point sources in the interstellar diffuse emission model."
}


@article{1748-0221-11-09-P09001,
  author={A. Aurisano and A. Radovic and D. Rocco and A. Himmel and M.D. Messier and E. Niner and G. Pawloski and F. Psihas and A. Sousa and P.
Vahle},
  title={A convolutional neural network neutrino event classifier},
  journal={Journal of Instrumentation},
  volume={11},
  number={09},
  pages={P09001},
  url={http://stacks.iop.org/1748-0221/11/i=09/a=P09001},
  year={2016},
  abstract={Convolutional neural networks (CNNs) have been widely applied in the computer vision community to solve complex problems in image recognition and analysis. We describe an application of the CNN technology to the problem of identifying particle interactions in sampling calorimeters used commonly in high energy physics and high energy neutrino physics in particular. Following a discussion of the core concepts of CNNs and recent innovations in CNN architectures related to the field of deep learning, we outline a specific application to the NOvA neutrino detector. This algorithm, CVN (Convolutional Visual Network) identifies neutrino interactions based on their topology without the need for detailed reconstruction and outperforms algorithms currently in use by the NOvA collaboration.}
}


@article{DBLP:journals/corr/abs-1711-08998,
  author    = {Christian F. Baumgartner and
               Lisa M. Koch and
               Kerem Can Tezcan and
               Jia Xi Ang and
               Ender Konukoglu},
  title     = {Visual Feature Attribution using Wasserstein GANs},
  journal   = {CoRR},
  volume    = {abs/1711.08998},
  year      = {2017},
  url       = {http://arxiv.org/abs/1711.08998},
  archivePrefix = {arXiv},
  eprint    = {1711.08998},
  timestamp = {Sun, 03 Dec 2017 12:38:15 +0100},
  biburl    = {http://dblp.org/rec/bib/journals/corr/abs-1711-08998},
  bibsource = {dblp computer science bibliography, http://dblp.org},
  abstract= "Attributing the pixels of an input image to a certain category is an important and well-studied problem in computer vision, with applications ranging from weakly supervised localisation to understanding hidden effects in the data. In recent years, approaches based on interpreting a previously trained neural network classifier have become the de facto state-of-the-art and are commonly used on medical as well as natural image datasets. In this paper, we discuss a limitation of these approaches which may lead to only a subset of the category specific features being detected. To address this problem we develop a novel feature attribution technique based on Wasserstein Generative Adversarial Networks (WGAN), which does not suffer from this limitation. We show that our proposed method performs substantially better than the state-of-the-art for visual attribution on a synthetic dataset and on real 3D neuroimaging data from patients with mild cognitive impairment (MCI) and Alzheimer's disease (AD). For AD patients the method produces compellingly realistic disease effect maps which are very close to the observed effects."
}

@conference{ICRC2017-Huennefeld,
  author       = {M. Huennefeld for the IceCube Collaboration},
  title        = {Deep Learning in Physics exemplified by the Reconstruction of Muon-Neutrino Events in IceCube},
  year         = 2017,
  publisher    = {Proceedings of Science},
  volume       = {301},
  note         = {(ICRC2017)1057},
  url          = {https://pos.sissa.it/301/1057/},
  abstract     = "Recent advances, especially in image recognition, have shown the capabilities of deep learning.
Deep neural networks can be extremely powerful and their usage is computationally inexpensive
once the networks are trained. While the main bottleneck for deep neural networks in the traditional
domain of image classification is the lack of sufficient labeled data, this usually does not
apply to physics where millions of Monte Carlo simulations exist.
The IceCube Neutrino Observatory is a Cherenkov detector deep in the Antarctic ice where the
reconstruction of muon-neutrino events is one of the key challenges. Due to limited computational
resources and the high data rate, only simplified reconstructions limited to a small subset of data
can be run on-site at the South Pole. However, in order to perform online analysis and to issue
real-time alerts, a fast and powerful reconstruction is necessary.
This paper demonstrates how deep learning techniques such as those used in image recognition
can be applied to IceCube pulses in order to reconstruct muon-neutrino events. These methods
can be generalized to other physics experiments."
}

@conference{ICRC2017-Holch,
  author       = {T.L. Holch and I. Shilon and M. Buchele and T. Fischer and S. Funk and N. Groeger and D. Jankowsky and T. Lohse and U. Schwanke and P. Wagner},
  title        = {Probing Convolutional Neural Networks for Event Reconstruction in Gamma-Ray Astronomy with Cherenkov Telescopes},
  year         = 2017,
  publisher    = {Proceedings of Science},
  volume       = {301},
  note         = {(ICRC2017)795},
  url          = {https://pos.sissa.it/301/795/},
  abstract     = "A dramatic progress in the field of computer vision has been made in recent years by applying deep learning techniques. State-of-the-art performance in image recognition is thereby reached with Convolutional Neural Networks (CNNs). CNNs are a powerful class of artificial neural networks, characterized by requiring fewer connections and free parameters than traditional neural networks and exploiting spatial symmetries in the input data. Moreover, CNNs have the ability to automatically extract general characteristic features from data sets and create abstract data representations which can perform very robust predictions. This suggests that experiments using Cherenkov telescopes could harness these powerful machine learning algorithms to improve the analysis of particle-induced air-showers, where the properties of primary shower particles are reconstructed from shower images recorded by the telescopes. In this work, we present initial results of a CNN-based analysis for background rejection and shower reconstruction, utilizing simulation data from the H.E.S.S. experiment. We concentrate on supervised training methods and outline the influence of image sampling on the performance of the CNN-model predictions."
}


@article{1748-0221-12-03-P03011,
  author={R. Acciarri and C. Adams and R. An and J. Asaadi and M. Auger and L. Bagby and B. Baller and G. Barr and M. Bass and F. Bay and M. Bishai and A.
Blake and T. Bolton and L. Bugel and L. Camilleri and D. Caratelli and B. Carls and R. Castillo Fernandez and F. Cavanna and H.
Chen and E. Church and D. Cianci and G.H. Collin and J.M. Conrad and M. Convery and J.I. Crespo-AnadÃ³n and M. Del Tutto and D.
Devitt and S. Dytman and B. Eberly and A. Ereditato and L. Escudero Sanchez and J. Esquivel and B.T. Fleming and W. Foreman and A.P.
Furmanski and G.T. Garvey and V. Genty and D. Goeldi and S. Gollapinni and N. Graf and E. Gramellini and H. Greenlee and R.
Grosso and R. Guenette and A. Hackenburg and P. Hamilton and O. Hen and J. Hewes and C. Hill and J. Ho and G. Horton-Smith and C.
James and J. Jan de Vries and C.-M. Jen and L. Jiang and R.A. Johnson and B.J.P. Jones and J. Joshi and H. Jostlein and D. Kaleko and G.
Karagiorgi and W. Ketchum and B. Kirby and M. Kirby and T. Kobilarcik and I. Kreslo and A. Laube and Y. Li and A. Lister and B.R.
Littlejohn and S. Lockwitz and D. Lorca and W.C. Louis and M. Luethi and B. Lundberg and X. Luo and A. Marchionni and C. Mariani and J.
Marshall and D.A. Martinez Caicedo and V. Meddage and T. Miceli and G.B. Mills and J. Moon and M. Mooney and C.D. Moore and J.
Mousseau and R. Murrells and D. Naples and P. Nienaber and J. Nowak and O. Palamara and V. Paolone and V. Papavassiliou and S.F.
Pate and Z. Pavlovic and D. Porzio and G. Pulliam and X. Qian and J.L. Raaf and A. Rafique and L. Rochester and C. Rudolf von
Rohr and B. Russell and D.W. Schmitz and A. Schukraft and W. Seligman and M.H. Shaevitz and J. Sinclair and E.L. Snider and M.
Soderberg and S. SÃ¶ldner-Rembold and S.R. Soleti and P. Spentzouris and J. Spitz and J. St. John and T. Strauss and A.M.
Szelc and N. Tagg and K. Terao and M. Thomson and M. Toups and Y.-T. Tsai and S. Tufanli and T. Usher and R.G. Van de Water and B.
Viren and M. Weber and J. Weston and D.A. Wickremasinghe and S. Wolbers and T. Wongjirad and K. Woodruff and T. Yang and G.P.
Zeller and J. Zennamo and C. Zhang},
  title={Convolutional neural networks applied to neutrino events in a liquid argon time projection chamber},
  journal={Journal of Instrumentation},
  volume={12},
  number={03},
  pages={P03011},
  url={http://stacks.iop.org/1748-0221/12/i=03/a=P03011},
  year={2017},
  abstract={We present several studies of convolutional neural networks applied to data coming from the MicroBooNE detector, a liquid argon time projection chamber (LArTPC). The algorithms studied include the classification of single particle images, the localization of single particle and neutrino interactions in an image, and the detection of a simulated neutrino event overlaid with cosmic ray backgrounds taken from real detector data. These studies demonstrate the potential of convolutional neural networks for particle identification or event detection on simulated neutrino interactions. We also address technical issues that arise when applying this technique to data from a large LArTPC at or near ground level.}
}
